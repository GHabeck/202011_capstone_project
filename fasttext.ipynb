{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification using Fasttext\n",
    "__Author: gregor Habeck__ with contributions from Julia Schäfer\n",
    "\n",
    "We test fasttext to test classification of spoiler reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install homebrew\n",
    "# in terminal:\n",
    "# ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\n",
    "# install wget\n",
    "# in terminal:\n",
    "# brew install wget\n",
    "# git clone https://github.com/facebookresearch/fastText.git\n",
    "# cd fastText\n",
    "# sudo python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import fasttext\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator to open json.gzip files\n",
    "# yields single lines\n",
    "def get_reviews(file):\n",
    "    '''\n",
    "    Generator will yield lines of the passed file\n",
    "    '''\n",
    "    with gzip.open(file, 'r') as f:\n",
    "        for l in f:\n",
    "            yield l\n",
    "    f.close()\n",
    "# fetch features\n",
    "def fetch_features(file, features):\n",
    "    '''\n",
    "    Provide a list of features you want to extract in a single run.\n",
    "    Returns a dictionary.\n",
    "    file: json.gzip file you want to scan\n",
    "    features: features to extract from data\n",
    "    only reviews written in english will be collected\n",
    "    '''\n",
    "    \n",
    "    feature_dict = defaultdict(list)    \n",
    "    reviews = get_reviews(file)\n",
    "    \n",
    "    for review in tqdm(reviews):\n",
    "        review_dict = json.loads(review)\n",
    "        language = review_dict.get('review_language_start')\n",
    "\n",
    "        if language != 'en': \n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            for f in features:\n",
    "                feature_dict[f].append(review_dict.get(f))\n",
    "        \n",
    "        \n",
    "    return pd.DataFrame.from_dict(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safe texts in a format suitable for fasttext\n",
    "# labels precede text in the form of __label__spoiler/ __label__safe\n",
    "def prepare_fasttext(dataframe, label):\n",
    "    with open(f'{label}_fasttext','w+') as tf:\n",
    "        for ind in tqdm(dataframe.index):\n",
    "            if dataframe['has_spoiler'][ind] == 1:\n",
    "                tf.write(f\"__label__spoiler {' '.join(dataframe['lemmatized'][ind])}\\n\")\n",
    "            elif dataframe['has_spoiler'][ind] == 0:\n",
    "                tf.write(f\"__label__safe {' '.join(dataframe['lemmatized'][ind])}\\n\")\n",
    "            else:\n",
    "                continue\n",
    "    tf.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = 'train_set_text_edit.json.gz'\n",
    "validation = 'validation_set_text_edit.json.gz'\n",
    "test = 'test_set_text_edit.json.gz'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "964623it [01:44, 9267.80it/s] \n",
      "100%|██████████| 893695/893695 [00:58<00:00, 15296.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# import training data\n",
    "isolate = ['has_spoiler', 'lemmatized']\n",
    "\n",
    "\n",
    "df_train = fetch_features(training, isolate)\n",
    "\n",
    "prepare_fasttext(df_train, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_spoiler</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[read review blog, , definitely well book, ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[write comment realize probably end long quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>[charlie turn young sister get marry, decide w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[like get implausible storyline read long time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[review originally post step fiction, want reb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_spoiler                                         lemmatized\n",
       "0        False  [read review blog, , definitely well book, ins...\n",
       "1        False  [write comment realize probably end long quali...\n",
       "2        False  [charlie turn young sister get marry, decide w...\n",
       "3        False  [like get implausible storyline read long time...\n",
       "4         True  [review originally post step fiction, want reb..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "275606it [00:26, 10562.93it/s]\n",
      "100%|██████████| 255227/255227 [00:15<00:00, 16792.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# import validation data\n",
    "\n",
    "df_val = fetch_features(validation, isolate)\n",
    "prepare_fasttext(df_val, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137804it [00:11, 11700.63it/s]\n",
      "100%|██████████| 127592/127592 [00:07<00:00, 17209.06it/s]\n"
     ]
    }
   ],
   "source": [
    "isolate = ['has_spoiler', 'lemmatized']\n",
    "df_test = fetch_features(test, isolate)\n",
    "prepare_fasttext(df_test, 'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:15:03'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple model using default settings\n",
    " \n",
    "\n",
    "t0 = time.time()\n",
    "model = fasttext.train_supervised(input='train_fasttext', epoch = 50, lr = 0.1, wordNgrams = 2,\n",
    "                                 loss = 'softmax')\n",
    "model.save_model('basis_fasttext_model.bin')\n",
    "elapsed_time = time.time()-t0\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test dataset\n",
      "For safe reviews:\n",
      " Precision: 0.93 \trecall: 0.93\n",
      "For spoiler reviews:\n",
      " Precision: 0.5 \trecall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on validation set\n",
    "safe_class = model.test('validation_fasttext', k =1)\n",
    "spoiler_class = model.test('validation_fasttext', k =2)\n",
    "\n",
    "print('For test dataset')\n",
    "print(f\"For safe reviews:\\n Precision: {round(safe_class[1],2)} \\trecall: {round(safe_class[2],2)}\")\n",
    "print(f\"For spoiler reviews:\\n Precision: {round(spoiler_class[1],2)} \\trecall: {round(spoiler_class[2],2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test dataset\n",
      "For safe reviews:\n",
      " Precision: 0.93 \trecall: 0.93\n",
      "For spoiler reviews:\n",
      " Precision: 0.5 \trecall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test data set\n",
    "safe_class = model.test('test_fasttext', k =1)\n",
    "spoiler_class = model.test('test_fasttext', k =2)\n",
    "\n",
    "print('For test dataset')\n",
    "print(f\"For safe reviews:\\n Precision: {round(safe_class[1],2)} \\trecall: {round(safe_class[2],2)}\")\n",
    "print(f\"For spoiler reviews:\\n Precision: {round(spoiler_class[1],2)} \\trecall: {round(spoiler_class[2],2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "That looks very suspicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict probability of spoiler review classification\n",
    "def predict_proba(model,text):\n",
    "    a = model.predict(text, k = -1)\n",
    "    return a[1][1]\n",
    "\n",
    "# predict spoiler from probability\n",
    "def prediction(proba):\n",
    "    if proba < 0.5:\n",
    "        return 0        \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join sentences in test dataset\n",
    "df_test['lemmatized'] = df_test['lemmatized'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set\n",
    "df_test['proba'] = df_test['lemmatized'].apply(lambda x: predict_proba(model1,x))\n",
    "df_test['prediction'] = df_test['proba'].apply(lambda x: prediction(model,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119203,      0],\n",
       "       [  8389,      0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test['has_spoiler'], df_test['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't match the results from fastText prediction. Try to optimize the model using autotune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Didn't have enough time to train once: please increase `autotune-duration`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-78044384ecc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model_autotune2 = fasttext.train_supervised(input = 'train_fasttext',epoch = 50, lr = 0.25, \n\u001b[0;32m----> 3\u001b[0;31m                                            autotuneValidationFile = 'validation_fasttext', autotuneDuration=600 )\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel_autotune2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autotune_fasttext_model2.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/fasttext-0.9.2-py3.6-macosx-10.9-x86_64.egg/fasttext/FastText.py\u001b[0m in \u001b[0;36mtrain_supervised\u001b[0;34m(*kargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanually_set_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FastText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mfasttext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Didn't have enough time to train once: please increase `autotune-duration`."
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "model_autotune = fasttext.train_supervised(input = 'train_fasttext', autotuneValidationFile = 'validation_fasttext')\n",
    "model_autotune.save_model('autotune_fasttext_model.bin')\n",
    "elapsed_time = time.time()-t0\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['proba_auto'] = df_test['lemmatized'].apply(lambda x: predict_proba(model_autotune,x))\n",
    "df_test['prediction_auto'] = df_test['proba_auto'].apply(lambda x: prediction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119200,      3],\n",
       "       [  8389,      0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_test['has_spoiler'], df_test['prediction_auto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did not help. We will next try to build our own word vectors based on the book descriptions and reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build own word vectors based on descriptions and spell checked reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "964623it [01:25, 11277.81it/s]\n",
      "275606it [00:42, 6538.74it/s] \n",
      "137804it [00:11, 12458.05it/s]\n"
     ]
    }
   ],
   "source": [
    "isolate = ['description', 'sentence_text_spellchecked']\n",
    "df_train = fetch_features(training, isolate)\n",
    "df_val = fetch_features(validation, isolate)\n",
    "df_test = fetch_features(test, isolate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1276514, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for text editing, replace contractions\n",
    "#https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "def decontracted(text):\n",
    "    # specific\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"let\\'s\", \"let us\", text)\n",
    "    \n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    #words\n",
    "    text = re.sub(\"gimme\", \"give me\", text)\n",
    "    text = re.sub(\"cuz\", \"because\", text)\n",
    "    text = re.sub(\"'cause\", \"give me\", text)\n",
    "    text = re.sub(\"finna\", \"fixing to\", text)\n",
    "    text = re.sub(\"cuz\", \"because\", text)\n",
    "    text = re.sub(\"wanna\", \"want to\", text)\n",
    "    text = re.sub(\"gotta\", \"got to\", text)\n",
    "    text = re.sub(\"hafta\", \"have to\", text)\n",
    "    text = re.sub(\"woulda\", \"would have\", text)\n",
    "    text = re.sub(\"coulda\", \"could have\", text)\n",
    "    text = re.sub(\"shoulda\", \"should have\", text)\n",
    "    text = re.sub(\"ma'am\", \"madam\", text)\n",
    "    text = re.sub(\"howdy\", \"how do you\", text)\n",
    "    text = re.sub(\"let's\", \"let us\", text)\n",
    "    text = re.sub(\"y'all\", \"you all\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# function to preprocess text\n",
    "def preprocessing(text):\n",
    "    t0 = time.time()\n",
    "    # remove '--' and replace them with whitespace\n",
    "    text = text.replace('-', ' ')\n",
    "    #change to lower case\n",
    "    text=text.lower()\n",
    "    # replace contractions\n",
    "    text = decontracted(text)\n",
    "    #remove urls if there are any\n",
    "    text = re.sub(r'http:\\S+', '', text)\n",
    "    text = re.sub(r'www\\S+', '', text)\n",
    "    #remove emails and words containing @\n",
    "    text = re.sub(\"\\S*@\\S*\\s?\",\" \", text)\n",
    "    # remove digits and words containing digits\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    #remove special characters and punctuation\n",
    "    text = re.sub(r'[(,;:@#&$!?.)\"*/-]+', ' ', text)\n",
    "    text = re.sub(r\"[']\", '', text)\n",
    "    # replace whitespaces\n",
    "    text = re.sub(r\"\\s+\", ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    try:\n",
    "        text = decontracted(text)\n",
    "        text = preprocessing(text)\n",
    "        return text\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>sentence_text_spellchecked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One choice can transform you--or it can destro...</td>\n",
       "      <td>[read this review on my blog, , definitely bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A novel of the cruelty of war, and tenuousness...</td>\n",
       "      <td>[i was writing a comment that i realized would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>[charlie is turning and her younger sister is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A ruthless businesswoman and the playboy who d...</td>\n",
       "      <td>[is more like it even though this has got to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Five years ago, Wren Connolly was shot three t...</td>\n",
       "      <td>[review originally posted at step into fiction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  One choice can transform you--or it can destro...   \n",
       "1  A novel of the cruelty of war, and tenuousness...   \n",
       "2                                               None   \n",
       "3  A ruthless businesswoman and the playboy who d...   \n",
       "4  Five years ago, Wren Connolly was shot three t...   \n",
       "\n",
       "                          sentence_text_spellchecked  \n",
       "0  [read this review on my blog, , definitely bet...  \n",
       "1  [i was writing a comment that i realized would...  \n",
       "2  [charlie is turning and her younger sister is ...  \n",
       "3  [is more like it even though this has got to b...  \n",
       "4  [review originally posted at step into fiction...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b50719a8c8a494db72d4ff20b3f4cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1276514.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# preprocess the descriptions\n",
    "import swifter\n",
    "df_all['description'] = df_all['description'].swifter.apply(lambda x: process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edeb113af6a64aaa98fd5166230833ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=1276514.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_all['sentence_text_spellchecked'] = df_all['sentence_text_spellchecked'].swifter.apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>sentence_text_spellchecked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one choice can transform you or it can destroy...</td>\n",
       "      <td>read this review on my blog  definitely better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a novel of the cruelty of war and tenuousness ...</td>\n",
       "      <td>i was writing a comment that i realized would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>charlie is turning and her younger sister is g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a ruthless businesswoman and the playboy who d...</td>\n",
       "      <td>is more like it even though this has got to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>five years ago wren connolly was shot three ti...</td>\n",
       "      <td>review originally posted at step into fiction ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  one choice can transform you or it can destroy...   \n",
       "1  a novel of the cruelty of war and tenuousness ...   \n",
       "2                                                      \n",
       "3  a ruthless businesswoman and the playboy who d...   \n",
       "4  five years ago wren connolly was shot three ti...   \n",
       "\n",
       "                          sentence_text_spellchecked  \n",
       "0  read this review on my blog  definitely better...  \n",
       "1  i was writing a comment that i realized would ...  \n",
       "2  charlie is turning and her younger sister is g...  \n",
       "3  is more like it even though this has got to be...  \n",
       "4  review originally posted at step into fiction ...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1276514/1276514 [2:04:24<00:00, 171.02it/s] \n"
     ]
    }
   ],
   "source": [
    "# write texts to file\n",
    "with open('fasttext_vector.txt', 'w+') as vec:\n",
    "    for ind in tqdm(df_all.index):\n",
    "        vec.write(f\"{df_all['description'][ind]}\\n\")\n",
    "        vec.write(f\"{df_all['sentence_text_spellchecked'][ind]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word vector model\n",
    "model_vec = fasttext.train_unsupervised('fasttext_vector.txt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word vector model\n",
    "model_vec.save_model('emb_model.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model_vec = fasttext.load_model('emb_model.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try sentence-wise classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "964623it [02:52, 5592.98it/s] \n"
     ]
    }
   ],
   "source": [
    "isolate = ['has_spoiler', 'sentence_labels', 'lemmatized']\n",
    "df_train = fetch_features(training, isolate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_spoiler</th>\n",
       "      <th>sentence_labels</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[read review blog, , definitely well book, ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[write comment realize probably end long quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[charlie turn young sister get marry, decide w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[like get implausible storyline read long time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[review originally post step fiction, want reb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_spoiler                                    sentence_labels  \\\n",
       "0        False  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1        False  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2        False                                       [0, 0, 0, 0]   \n",
       "3        False                                       [0, 0, 0, 0]   \n",
       "4         True  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [read review blog, , definitely well book, ins...  \n",
       "1  [write comment realize probably end long quali...  \n",
       "2  [charlie turn young sister get marry, decide w...  \n",
       "3  [like get implausible storyline read long time...  \n",
       "4  [review originally post step fiction, want reb...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58428/58428 [00:06<00:00, 9339.81it/s] \n",
      "100%|██████████| 58428/58428 [00:01<00:00, 38503.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# isolate sentences and labels from spoiler reviews\n",
    "df_spoiler = df_train[df_train['has_spoiler']==True]\n",
    "sentences = []\n",
    "for review in tqdm(df_spoiler['lemmatized']):\n",
    "    for sentence in review:\n",
    "        sentences.append(sentence)\n",
    "\n",
    "labels = []\n",
    "for review in tqdm(df_spoiler['sentence_labels']):\n",
    "    for label in review:\n",
    "        labels.append(label)\n",
    "\n",
    "\n",
    "df_sentences = pd.DataFrame({\n",
    "    'has_spoiler': labels,\n",
    "    'sentences': sentences\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_spoiler</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>review originally post step fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>want reboot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sure want low number high number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>lean high number bit kickass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>high number mean long dead reboot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_spoiler                            sentences\n",
       "0            0  review originally post step fiction\n",
       "1            0                          want reboot\n",
       "2            0     sure want low number high number\n",
       "3            0         lean high number bit kickass\n",
       "4            0    high number mean long dead reboot"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences = df_sentences.drop_duplicates(['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 42\n",
    "\n",
    "X=df_sentences['sentences']\n",
    "y = df_sentences['has_spoiler']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state = random_state, stratify= y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.15, random_state=random_state, stratify= y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_train = pd.DataFrame({'sentences':X_train, 'label':y_train})\n",
    "df_sentence_val = pd.DataFrame({'sentences':X_val, 'label':y_val})\n",
    "df_sentence_test = pd.DataFrame({'sentences':X_test, 'label':y_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741636, 2)\n",
      "(290838, 2)\n",
      "(130877, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_sentence_train.shape)\n",
    "print(df_sentence_val.shape)\n",
    "print(df_sentence_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fasttext_sen(dataframe, label):\n",
    "    with open(f'{label}_sentence_fasttext','w+') as tf:\n",
    "        for ind in tqdm(dataframe.index):\n",
    "            if dataframe['label'][ind] == 1:\n",
    "                tf.write(f\"__label__spoiler {dataframe['sentences'][ind]}\\n\")\n",
    "            elif dataframe['label'][ind] == 0:\n",
    "                tf.write(f\"__label__safe {dataframe['sentences'][ind]}\\n\")\n",
    "            else:\n",
    "                continue\n",
    "    tf.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 741636/741636 [00:29<00:00, 24900.83it/s]\n",
      "100%|██████████| 290838/290838 [00:11<00:00, 26393.82it/s]\n",
      "100%|██████████| 130877/130877 [00:05<00:00, 24111.15it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_fasttext_sen(df_sentence_train, 'train')\n",
    "prep_fasttext_sen(df_sentence_val, 'val')\n",
    "prep_fasttext_sen(df_sentence_test, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train fasttext classification models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00:06:10'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "s_model_autotune = fasttext.train_supervised(input = 'train_sentence_fasttext', epoch = 40, lr = 0.25,\n",
    "                                             autotuneValidationFile = 'val_sentence_fasttext')\n",
    "s_model_autotune.save_model('sentence_autotune_fasttext_model.bin')\n",
    "elapsed_time = time.time()-t0\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741636, 0.7654981689130517, 0.7654981689130517)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model_autotune.test('train_sentence_fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentence_test['probability'] = df_sentence_test['sentences'].apply(lambda x: predict_proba(s_model_autotune,x))\n",
    "df_sentence_test['prediction'] = df_sentence_test['probability'].apply(lambda x: prediction(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[95305,     2],\n",
       "       [35568,     2]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_sentence_test['label'] , df_sentence_test['prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification of spoiler sentences also did not work. Assuming we did not make mistakes, Fasttext classification is not well suited for our problem.   \n",
    "Just to make sure that we have used fasttext correctly, we should try our code on a different dataset with clearly separated classes (sentiment, politics news vs. entertainment news)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
